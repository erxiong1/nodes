# 搜索引擎杂记

NLP自然语言处理

  

![img](https://images2017.cnblogs.com/blog/1120165/201708/1120165-20170823213846668-1108166981.png)

![img](https://pic3.zhimg.com/80/v2-6721c7926c41534d491d964a8183338a_720w.jpg)

搜索引擎一般都有一个Robot定期的访问一些站点，来检查这些站点的变化，同时查找新的站点。一般站点有一个robot.txt文件用来说明服务器不希望Robot访问的区域，Robot 都必须遵守这个规定。如果是自动索引的话，Robot在得到页面以后，需要对该页面根据其内容进行索引，根据它的关键字的情况把它归到某一类中

定时爬取



每次发起请求，我们都是根据url发起请求，而这个过程中会牵涉到DNS解析，将url转换成ip地址。一个网站通常由成千上万的URL，因此，我们可以考虑将这些网站域名的IP地址进行缓存，避免每次都发起DNS请求，费时费力。



**3）DNS缓存**

为了避免每次都发起DNS查询，我们可以将DNS进行缓存。[DNS缓存](https://www.zhihu.com/search?q=DNS缓存&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A23276456})当然是设计一个hash表来存储已有的域名及其IP。



**4）网页去重**

说到网页去重，第一个想到的是垃圾邮件过滤。[垃圾邮件](https://www.zhihu.com/search?q=垃圾邮件&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A23276456})过滤一个经典的解决方案是Bloom Filter（[布隆过滤器](https://www.zhihu.com/search?q=布隆过滤器&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A23276456})）。布隆过滤器原理简单来说就是：建立一个大的位数组，然后用多个Hash函数对同一个url进行hash得到多个数字，然后将位数组中这些数字对应的位置为1。下次再来一个url时，同样是用多个Hash函数进行hash，得到多个数字，我们只需要判断位数组中这些数字对应的为是全为1，如果全为1，那么说明这个url已经出现过。如此，便完成了url去重的问题。当然，这种方法会有误差，只要误差在我们的容忍范围之类，比如1万个网页，我只爬取到了9999个，剩下那一个网页，who cares！



线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的[系统函数](https://www.zhihu.com/search?q=系统函数&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A23488863})。



现在的多线程一般使用线程池，可以让线程的创建和回收成本相对较低，在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一连接专注之间的I/o并切编程模型简单，也不用考虑系统的过载，限流等问题，线程本身就是一个天然的漏斗，可以缓冲一些系统处理不来的连接或请求。



不过这个模型的问题最本质问题在于，严重依赖与线程。单线程是很"贵"的资源，主要表现在：

1. 线程的创建和小会成本很高，在Linux这样的操作系统中，线程本质就是一个进程。创建和小会都是重量级别的系统函数。
2. 线程本身占用较大的内存，想Java的线程栈，一般至少分配512K-1M的空间，如果系统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半。
3. 线程的切换成本是很高的。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间会大于线程执行的时间，这时候带来的表现往往是系统load偏高，CPU 使用率特别搞（超过20%以上），导致系统几乎陷入不可用的状态。
4. 容易造成锯齿状的系统负载。应为系统负载是用活动线程数或者CPU核心数，一旦线程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结构同时返回，激活大量阻塞线程从而使系统负载压力过大。

所以，当面对十万甚至百万级连接的时候，传统的BIO模型是无能威力的。随着移动端的兴起和各种网络游戏的盛行，百万级长连接日趋普遍，此时，必然要一种更高效的I/O处理模型。



## 常见的I/O模型对呗

所有的系统I/O都分为两个阶段：等待就绪和操作。

读函数：分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。

> 等待就绪的阻塞是不使用CPU的，是在”空等“；而真正的读写操作是阻塞是使用CPU的，真正在”干活“而且这个过程非常快，属于memory copy,宽带通常在1GB/s级别以上,可以理解为基本不耗时。
>
>  





https://m.tongfu.net/home/35/blog/512795.html





![](https://s2.loli.net/2021/12/14/ZOtfSGDMrnCLxJB.png)

https://www.zhihu.com/question/19937854/answer/61704536

![](https://s2.loli.net/2021/12/14/PbuL1pvFZOc9tgj.png)

## 增量爬虫

> 概念：通过爬虫程序检测某网站的数据更新情况，以便爬去到该网站更新出的新的数据。
>
> + 如何进行增量式的爬去工作，检测重复数据的三种情况：
>   + 在发送请求之前判断这个URL是不是之前爬取过
>   + 在解析内容判断这部分内容是不是之前爬去过
>   + 写入存储介质时候判断内容是不是已经存在介质中存在过
> + 分析：
>   + 不难发现，其实增量式爬虫的核心就是**去重**，至于去重的操作在哪个步骤其作用，各有利弊，前两种思路需要根据实际情况取一个（可能也能用）。第一种思路适合不断有新页面出现的网站，比如小说的新章节，每天的最新的新闻等待；第二章思路则适合页面内容会更新的网站。第三个思路是相当于最后一个防线。这样做可以最大程度上的达到去重的目的。
> + 去重的方法：
>   + 将爬去过程中产生的**url进行存储**，存储在redis的set中。当下次进行数据爬去时，首先对即将发起的请求对于的url在存储的url的set做判断，如果存在就不进行请求，否则进行请求。
>   + 对爬取到的网页内容进行唯一**标识的指定(数据指纹)例如MD5，sha等摘要算法做标识**，然后将唯一表示存储至redis的set中。当下次爬取到网页数据的时候，首先可以判断该数据的唯一标识在redis的set中是否存在，在决定是否进行持久化存储。

## 通用爬虫

> 通用爬虫又称全网爬虫(Scalable Web Crawler)，它将爬取对象从一些种子URL扩充到整个Web上的网站,主要用途是为门户站点搜索引擎和大型Web服务器提供商业采集数据。这类网络爬虫的爬行范围和数量巨大，对于爬行速度和存储空间要求极高，对于爬行页面的顺序要求相对较底，同时由于带刷新的页面太多，通常采用并行工作方式,单需要较长的时间才能刷新一次。

**1. 累积式爬虫**

累积式爬虫是指从某一个时间点开始，通过遍历的方式抓取系统所能允许存储和处理的所有网页。在理想的软硬件环境下，经过足够的运行时间，累积式抓取的策略可以保证抓取到相当规模的网页集合。但由于Web数据的动态特性，集合中网页的被抓取时间点是不同的，页面被更新的情况也不同，因此累积式抓取到的网页集合事实上并无法与真实环境中的网络数据保持一致。

**2. 增量式爬虫**

增量式网络爬虫(Incremental Web Crawler)是指在具有一定量规模的网络页面集合的基础上，采用更新数据的方式选取已有集合中的过时网页进行抓取，以保证所抓取到的数据与真实网络数据足够接近。进行增量式抓取的前提是，系统已经抓取了足够数量的网络页面，并具有这些页面被抓取的时间信息。

和周期性爬行和刷新页面的网络爬虫相比，增量式爬虫只会在需要的时候爬行新产生或发生更新的页面，并不重新下载没有发生变化的页面，可有效减少数据下载量，及时更新已爬行的网页，减小时间和空间上的耗费，但是增加了爬行算法的复杂度和实现难度。

面向实际应用环境的网络蜘蛛设计中，通常既包括累积式抓取，也包括增量式抓取的策略。累积式抓取一般用于数据集合的整体建立或大规模更新阶段;而增量式抓取则主要针对数据集合的日常维护与即时更新。